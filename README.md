**VidNexus: YouTube Video Assistant with AI Response Generation**
=======================================================

This project allows you to query YouTube video transcripts and generate AI-based responses using Google's Gemini API. The backend uses Langchain for document loading and splitting, FAISS for vector storage, and a pre-trained model to generate responses based on YouTube video transcripts.

The project includes:

-   **Backend**: Python-based logic to extract transcripts, split them into chunks, and store them in a FAISS vector database.
-   **Frontend**: A Streamlit-based interface to interact with the assistant and ask queries about YouTube videos.

* * * * *

**Features**
------------

-   **Video Transcript Extraction**: Extracts transcripts from YouTube videos using the YouTube Transcript API and Pytube.
-   **Text Chunking**: Breaks down video transcripts into smaller chunks for efficient querying and processing.
-   **AI-Based Query Answering**: Uses Google Gemini API to provide detailed answers based on the video's transcript.
-   **Streamlit Frontend**: A simple user interface to interact with the assistant.

* * * * *

**Technologies Used**
---------------------

-   **Langchain**: For handling document loading, splitting, and vector storage.
-   **Google Gemini API**: For generative AI model-based answers.
-   **Pytube**: For extracting video metadata and ID from YouTube links.
-   **YouTube Transcript API**: For extracting video transcripts.
-   **FAISS**: For storing and retrieving video transcript chunks in a vector database.
-   **Streamlit**: For creating a simple and interactive frontend interface.

* * * * *

**Installation**
----------------

### 1\. Clone the repository:

`git clone https://github.com/mohd-anas-ansari-666/VidNexus_Yt_Assitant.git
cd VidNexus_Yt_Assitant`

### 2\. Install dependencies:

Create and activate a virtual environment:

```
python -m venv venv
source venv/bin/activate   # On Windows, use `venv\Scripts\activate`
```

Install the required Python libraries

### 3\. Set up environment variables:

Create a `.env` file in the root directory of the project and add your **Gemini API Key**:

`GEMINI_API_KEY=your_gemini_api_key`

### 4\. Run the backend with Streamlit:

Make sure you're in the project directory and run the Streamlit app:

`streamlit run streamlit_app.py`

This will launch the Streamlit app in your browser at `http://localhost:8501`.

* * * * *

**How it Works**
----------------

### 1\. **Create a FAISS Vector Database from a YouTube Video**

The function `create_db_from_youtube_video_url` takes a YouTube video URL, extracts its transcript, splits it into chunks, and creates a vector database using FAISS.

### 2\. **Ask a Query Based on the Video**

Once you have the FAISS vector database, you can query the database using `get_response_from_query`. This function retrieves relevant document chunks and generates an AI response using Google's Gemini model.

### 3\. **Frontend Interface**

The Streamlit frontend provides a simple interface where you can input a YouTube URL, create a vector database, and ask queries related to the video content. The responses are generated using the context of the transcript.

* * * * *

**Usage Example**
-----------------

Here's how the code can be used interactively via the Streamlit interface:

1.  **Enter a YouTube Video URL**: Paste the link of a YouTube video in the input field.
2.  **Create Database**: Click the button to create the FAISS vector database.
3.  **Ask Questions**: Once the database is created, enter your query (e.g., "What is the main topic of this video?") to get a response generated by the AI model.

* * * * *

**Code Walkthrough**
--------------------

-   **Backend (yt_info_extractor.py)**:

    -   **create_db_from_youtube_video_url(video_url)**: Extracts and splits the video transcript, creates a FAISS database.
    -   **get_response_from_query(db, query, k=4)**: Uses the FAISS database to retrieve relevant document chunks and generates a response with the AI model.
-   **Streamlit Interface**: Provides a web interface for interacting with the assistant.

* * * * *

**Contributing**
----------------

We welcome contributions! If you'd like to improve the functionality or add new features, feel free to open a pull request.

### Steps to Contribute:

1.  Fork the repository.
2.  Create a new branch (`git checkout -b feature-branch`).
3.  Make your changes.
4.  Commit your changes (`git commit -am 'Add new feature'`).
5.  Push to your branch (`git push origin feature-branch`).
6.  Open a pull request.

**Contact**
-----------

For any questions or suggestions, feel free to reach out at:\
Email: `mohdanasansari900@gmail.com`\
GitHub: [Link](https://github.com/mohd-anas-ansari-666)
